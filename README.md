# Video-Caption-Model

# Model
Encoder Decoder model that uses video as input and generated caption as output. This would be helpful in searching videos in websites better. Also can be used to cluster videos together that can be used in recomender systems. 

# Dataset 
This project is build on the MSVD dataset. It contains 1450 training videos and 100 testing videos. (Features also present extracted using VGG16)

# Accuracy 
Validation accuracy of 0.72

# Future Development
Adding attention modules
Web app deployment
Using other pretrained models so that longer videos could be processed

# References 
[SV2T paper 2015](https://arxiv.org/abs/1505.00487)

[Keras Implementation](https://github.com/CryoliteZ/Video2Text)
